# Speech-Emotion-Recognition-using-MLP-Classifier
Description:
This project focuses on recognizing emotions from speech signals using a Multi-Layer Perceptron (MLP) classifier. The system extracts features such as Mel-frequency cepstral coefficients (MFCCs), chroma, and mel spectrograms from audio clips to train the model. The dataset used includes emotions like anger, disgust, fear, happy, sad, sarcastic, and surprise. The model achieves an accuracy of approximately 82% and is evaluated using a confusion matrix and classification report. Additionally, the project includes testing with real-life audio clips to demonstrate practical applicability.

**Key Features:**

Feature extraction using Librosa.

MLP-based classification for emotion detection.

Evaluation metrics including accuracy, confusion matrix, and classification report.

Real-world testing with custom audio clips.

**Tools/Libraries**: Python, Librosa, Scikit-learn, NumPy, Matplotlib, Seaborn.

This project is ideal for understanding speech emotion recognition and can be extended for applications in human-computer interaction, mental health monitoring, and more.
